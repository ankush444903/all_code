{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avarage code for prep_guru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import PyPDF2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def process(self, text):\n",
    "        self.memory.chat_memory.add_user_message(text)\n",
    "        start_time = time.time()\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        return response['text']\n",
    "\n",
    "    def load_resume(self, resume_path):\n",
    "        with open(resume_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            resume_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                resume_text += page.extract_text()\n",
    "        return resume_text.strip()\n",
    "\n",
    "    def save_memory(self, filepath='conversation_memory.pkl'):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.memory, f)\n",
    "        print(f\"Memory saved to {filepath}\")\n",
    "\n",
    "    def load_memory(self, filepath='conversation_memory.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.memory = pickle.load(f)\n",
    "            print(f\"Memory loaded from {filepath}\")\n",
    "        else:\n",
    "            print(f\"No memory file found at {filepath}, starting fresh.\")\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "    def load_conversation(self, filepath='conversation_log.txt'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as log_file:\n",
    "                previous_conversation = log_file.read()\n",
    "            print(\"Previous conversation loaded:\\n\", previous_conversation)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Unable to load conversation_log.txt. I don't have your last information available.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def setup_azure_speech(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"en-IN\"\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000')\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '3000')\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_recognizer\n",
    "\n",
    "\n",
    "def setup_azure_tts(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-IN-AaravNeural'\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_synthesizer\n",
    "\n",
    "\n",
    "def text_to_speech(text, speech_synthesizer):\n",
    "    ssml_text = f\"\"\"\n",
    "    <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-IN'>\n",
    "        <voice name='en-IN-AaravNeural'>\n",
    "            <prosody rate='medium'>\n",
    "                {text}\n",
    "            </prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesis complete\")\n",
    "        else:\n",
    "            print(f\"Speech synthesis failed: {speech_synthesis_result.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "        self.region = os.getenv(\"AZURE_REGION\")\n",
    "        self.speech_recognizer = setup_azure_speech(self.api_key, self.region)\n",
    "        self.speech_synthesizer = setup_azure_tts(self.api_key, self.region)\n",
    "        self.is_running = True\n",
    "\n",
    "    async def listen_for_speech(self):\n",
    "        print(\"Listening...\")\n",
    "        result = await self.recognize_speech()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        return None\n",
    "\n",
    "    async def recognize_speech(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        future = loop.create_future()\n",
    "\n",
    "        def recognized_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_result, evt.result)\n",
    "\n",
    "        def canceled_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_exception, Exception(f\"Speech recognition canceled: {evt.reason}\"))\n",
    "\n",
    "        self.speech_recognizer.recognized.connect(recognized_cb)\n",
    "        self.speech_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "        await loop.run_in_executor(None, self.speech_recognizer.start_continuous_recognition)\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(future, timeout=180.0)  # 180 second timeout\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Speech recognition timed out\")\n",
    "            result = None\n",
    "        finally:\n",
    "            await loop.run_in_executor(None, self.speech_recognizer.stop_continuous_recognition)\n",
    "\n",
    "        return result\n",
    "\n",
    "    async def ask_for_introduction(self):\n",
    "        # First introduction\n",
    "        intro_prompt = \"Please introduce yourself.\"\n",
    "        print(f\"AI: {intro_prompt}\")\n",
    "        text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "        user_intro1 = await self.listen_for_speech()\n",
    "        if user_intro1:\n",
    "            print(f\"User: {user_intro1}\")\n",
    "            feedback_intro1 = self.llm.process(user_intro1)\n",
    "            print(f\"AI: {feedback_intro1}\")\n",
    "            text_to_speech(feedback_intro1, self.speech_synthesizer)\n",
    "\n",
    "        # Second introduction\n",
    "        intro_prompt_2 = \"Please introduce yourself again, sharing more details.\"\n",
    "        print(f\"AI: {intro_prompt_2}\")\n",
    "        text_to_speech(intro_prompt_2, self.speech_synthesizer)\n",
    "\n",
    "        user_intro2 = await self.listen_for_speech()\n",
    "        if user_intro2:\n",
    "            print(f\"User: {user_intro2}\")\n",
    "            feedback_intro2 = self.llm.process(user_intro2)\n",
    "            print(f\"AI: {feedback_intro2}\")\n",
    "            text_to_speech(feedback_intro2, self.speech_synthesizer)\n",
    "\n",
    "    async def ask_questions_based_on_resume(self, resume_text):\n",
    "        questions_prompt = f\"Based on the following resume, please ask relevant questions: {resume_text}\"\n",
    "        questions = self.llm.process(questions_prompt)\n",
    "        print(f\"AI: {questions}\")\n",
    "        text_to_speech(questions, self.speech_synthesizer)\n",
    "\n",
    "        while True:\n",
    "            user_response = await self.listen_for_speech()\n",
    "            if user_response:\n",
    "                print(f\"User: {user_response}\")\n",
    "                feedback = self.llm.process(user_response)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    async def main(self):\n",
    "        # Start with the welcome message\n",
    "        welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "        print(f\"AI: {welcome_message}\")\n",
    "        text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "        # Ask for the introduction twice\n",
    "        await self.ask_for_introduction()\n",
    "\n",
    "        # Load resume and process it after introductions\n",
    "        resume_path = r\"Resume\\Ankush Mahore.pdf\"  # Adjust this path to your resume file\n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume\n",
    "        await self.ask_questions_based_on_resume(resume_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code ask quation best way on resume  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import PyPDF2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def process(self, text):\n",
    "        self.memory.chat_memory.add_user_message(text)\n",
    "        start_time = time.time()\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        return response['text']\n",
    "\n",
    "    def load_resume(self, resume_path):\n",
    "        with open(resume_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            resume_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                resume_text += page.extract_text()\n",
    "        return resume_text.strip()\n",
    "\n",
    "    def save_memory(self, filepath='conversation_memory.pkl'):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.memory, f)\n",
    "        print(f\"Memory saved to {filepath}\")\n",
    "\n",
    "    def load_memory(self, filepath='conversation_memory.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.memory = pickle.load(f)\n",
    "            print(f\"Memory loaded from {filepath}\")\n",
    "        else:\n",
    "            print(f\"No memory file found at {filepath}, starting fresh.\")\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "    def load_conversation(self, filepath='conversation_log.txt'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as log_file:\n",
    "                previous_conversation = log_file.read()\n",
    "            print(\"Previous conversation loaded:\\n\", previous_conversation)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Unable to load conversation_log.txt. I don't have your last information available.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def setup_azure_speech(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"en-IN\"\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000')\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '3000')\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_recognizer\n",
    "\n",
    "\n",
    "def setup_azure_tts(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-IN-AaravNeural'\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_synthesizer\n",
    "\n",
    "\n",
    "def text_to_speech(text, speech_synthesizer):\n",
    "    ssml_text = f\"\"\"\n",
    "    <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-IN'>\n",
    "        <voice name='en-IN-AaravNeural'>\n",
    "            <prosody rate='medium'>\n",
    "                {text}\n",
    "            </prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesis complete\")\n",
    "        else:\n",
    "            print(f\"Speech synthesis failed: {speech_synthesis_result.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "        self.region = os.getenv(\"AZURE_REGION\")\n",
    "        self.speech_recognizer = setup_azure_speech(self.api_key, self.region)\n",
    "        self.speech_synthesizer = setup_azure_tts(self.api_key, self.region)\n",
    "        self.is_running = True\n",
    "\n",
    "    async def listen_for_speech(self):\n",
    "        print(\"Listening...\")\n",
    "        result = await self.recognize_speech()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        return None\n",
    "\n",
    "    async def recognize_speech(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        future = loop.create_future()\n",
    "\n",
    "        def recognized_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_result, evt.result)\n",
    "\n",
    "        def canceled_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_exception, Exception(f\"Speech recognition canceled: {evt.reason}\"))\n",
    "\n",
    "        self.speech_recognizer.recognized.connect(recognized_cb)\n",
    "        self.speech_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "        await loop.run_in_executor(None, self.speech_recognizer.start_continuous_recognition)\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(future, timeout=180.0)  # 180 second timeout\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Speech recognition timed out\")\n",
    "            result = None\n",
    "        finally:\n",
    "            await loop.run_in_executor(None, self.speech_recognizer.stop_continuous_recognition)\n",
    "\n",
    "        return result\n",
    "\n",
    "    async def ask_for_introduction(self):\n",
    "        iteration_count = 0\n",
    "        feedback = \"\"\n",
    "\n",
    "        while \"good\" not in feedback.lower() and iteration_count < 2:\n",
    "            # First introduction\n",
    "            intro_prompt = \"Please introduce yourself.\"\n",
    "            print(f\"AI: {intro_prompt}\")\n",
    "            text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "            user_intro = await self.listen_for_speech()\n",
    "            if user_intro:\n",
    "                print(f\"User: {user_intro}\")\n",
    "                feedback = self.llm.process(user_intro)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "            iteration_count += 1\n",
    "\n",
    "        # After 2 iterations, suggest practice and move on\n",
    "        if \"good\" not in feedback.lower():\n",
    "            text_to_speech(\"Please practice this introduction more. Let's move on to the next question.\", self.speech_synthesizer)\n",
    "\n",
    "\n",
    "    async def ask_questions_based_on_resume(self, resume_text):\n",
    "        questions_prompt = f\"Based on the following resume, please ask relevant questions: {resume_text}\"\n",
    "        questions = self.llm.process(questions_prompt)\n",
    "        print(f\"AI: {questions}\")\n",
    "        text_to_speech(questions, self.speech_synthesizer)\n",
    "\n",
    "        while True:\n",
    "            user_response = await self.listen_for_speech()\n",
    "            if user_response:\n",
    "                print(f\"User: {user_response}\")\n",
    "                feedback = self.llm.process(user_response)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    async def main(self):\n",
    "        # Start with the welcome message\n",
    "        welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "        print(f\"AI: {welcome_message}\")\n",
    "        text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "        # Ask for the introduction twice\n",
    "        await self.ask_for_introduction()\n",
    "\n",
    "        # Load resume and process it after introductions\n",
    "        resume_path = r\"Resume\\Ankush Mahore.pdf\"  # Adjust this path to your resume file\n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume\n",
    "        await self.ask_questions_based_on_resume(resume_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code make mistake in introducatin part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import PyPDF2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def process(self, text):\n",
    "        self.memory.chat_memory.add_user_message(text)\n",
    "        start_time = time.time()\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        return response['text']\n",
    "\n",
    "    def load_resume(self, resume_path):\n",
    "        with open(resume_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            resume_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                resume_text += page.extract_text()\n",
    "        return resume_text.strip()\n",
    "\n",
    "    def save_memory(self, filepath='conversation_memory.pkl'):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.memory, f)\n",
    "        print(f\"Memory saved to {filepath}\")\n",
    "\n",
    "    def load_memory(self, filepath='conversation_memory.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.memory = pickle.load(f)\n",
    "            print(f\"Memory loaded from {filepath}\")\n",
    "        else:\n",
    "            print(f\"No memory file found at {filepath}, starting fresh.\")\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "    def load_conversation(self, filepath='conversation_log.txt'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as log_file:\n",
    "                previous_conversation = log_file.read()\n",
    "            print(\"Previous conversation loaded:\\n\", previous_conversation)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Unable to load conversation_log.txt. I don't have your last information available.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def setup_azure_speech(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"en-IN\"\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000')\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '3000')\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_recognizer\n",
    "\n",
    "\n",
    "def setup_azure_tts(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-IN-AaravNeural'\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_synthesizer\n",
    "\n",
    "\n",
    "def text_to_speech(text, speech_synthesizer):\n",
    "    ssml_text = f\"\"\"\n",
    "    <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-IN'>\n",
    "        <voice name='en-IN-AaravNeural'>\n",
    "            <prosody rate='medium'>\n",
    "                {text}\n",
    "            </prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesis complete\")\n",
    "        else:\n",
    "            print(f\"Speech synthesis failed: {speech_synthesis_result.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "        self.region = os.getenv(\"AZURE_REGION\")\n",
    "        self.speech_recognizer = setup_azure_speech(self.api_key, self.region)\n",
    "        self.speech_synthesizer = setup_azure_tts(self.api_key, self.region)\n",
    "        self.is_running = True\n",
    "\n",
    "    async def listen_for_speech(self):\n",
    "        print(\"Listening...\")\n",
    "        result = await self.recognize_speech()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        return None\n",
    "\n",
    "    async def recognize_speech(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        future = loop.create_future()\n",
    "\n",
    "        def recognized_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_result, evt.result)\n",
    "\n",
    "        def canceled_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_exception, Exception(f\"Speech recognition canceled: {evt.reason}\"))\n",
    "\n",
    "        self.speech_recognizer.recognized.connect(recognized_cb)\n",
    "        self.speech_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "        await loop.run_in_executor(None, self.speech_recognizer.start_continuous_recognition)\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(future, timeout=180.0)  # 180 second timeout\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Speech recognition timed out\")\n",
    "            result = None\n",
    "        finally:\n",
    "            await loop.run_in_executor(None, self.speech_recognizer.stop_continuous_recognition)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # async def ask_for_introduction(self):\n",
    "    #     iteration_count = 0\n",
    "    #     feedback = \"\"\n",
    "\n",
    "    #     while \"good\" not in feedback.lower() and iteration_count < 2:\n",
    "    #         # First introduction\n",
    "    #         intro_prompt = \"Please introduce yourself.\"\n",
    "    #         print(f\"AI: {intro_prompt}\")\n",
    "    #         text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "    #         user_intro = await self.listen_for_speech()\n",
    "    #         if user_intro:\n",
    "    #             print(f\"User: {user_intro}\")\n",
    "    #             feedback = self.llm.process(user_intro)\n",
    "    #             print(f\"AI: {feedback}\")\n",
    "    #             text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    #         iteration_count += 1\n",
    "\n",
    "    \n",
    "    # async def ask_for_introduction(self):\n",
    "    #     iteration_count = 0  # To count the number of attempts\n",
    "\n",
    "    # while iteration_count < 3:  # Allow for up to 3 attempts\n",
    "    #     # Step 1: Ask for introduction\n",
    "    #     intro_prompt = \"Please introduce yourself.\"\n",
    "    #     print(f\"AI: {intro_prompt}\")\n",
    "    #     text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "    #     # Capture user's introduction\n",
    "    #     user_intro = await self.listen_for_speech()\n",
    "    #     if user_intro:\n",
    "    #         print(f\"User: {user_intro}\")\n",
    "\n",
    "    #         # Step 2: Analyze user's introduction and give feedback\n",
    "    #         feedback = self.llm.process(f\"Here is an introduction: {user_intro}. Give me feedback on the introduction, what is good, and what is missing.\")\n",
    "    #         print(f\"AI Feedback: {feedback}\")\n",
    "    #         text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    #         # Step 3: Check if feedback is satisfactory\n",
    "    #         if \"good\" in feedback.lower():\n",
    "    #             print(\"Feedback was satisfactory.\")\n",
    "    #             break  # Exit loop if feedback is satisfactory\n",
    "    #         else:\n",
    "    #             print(\"Your introduction needs improvement.\")\n",
    "    #             text_to_speech(\"Your introduction needs improvement. Please try again.\", self.speech_synthesizer)\n",
    "    #     else:\n",
    "    #         print(\"No valid introduction received. Please try again.\")\n",
    "    #         text_to_speech(\"No valid introduction received. Please try again.\", self.speech_synthesizer)\n",
    "\n",
    "    #     iteration_count += 1  # Increment the attempt count\n",
    "\n",
    "    # # After 3 attempts, provide final feedback\n",
    "    # if iteration_count == 3:\n",
    "    #     practice_feedback = \"You have made three attempts. Please practice your introduction more.\"\n",
    "    #     print(practice_feedback)\n",
    "    #     text_to_speech(practice_feedback, self.speech_synthesizer)\n",
    "\n",
    "################################################################\n",
    "    async def ask_for_introduction(self):\n",
    "        iteration_count = 0  # To count the number of attempts\n",
    "\n",
    "        while iteration_count < 3:  # Allow for up to 3 attempts\n",
    "            # Step 1: Ask for introduction\n",
    "            intro_prompt = \"Please introduce yourself.\"\n",
    "            print(f\"AI: {intro_prompt}\")\n",
    "            text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "            # Capture user's introduction\n",
    "            user_intro = await self.listen_for_speech()\n",
    "            if user_intro:\n",
    "                print(f\"User: {user_intro}\")\n",
    "\n",
    "                # Step 2: Analyze user's introduction and give feedback\n",
    "                feedback = self.llm.process(f\"Here is an introduction: {user_intro}. Give me feedback on the introduction, what is good, and what is missing.\")\n",
    "                print(f\"AI Feedback: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "                # Step 3: Check if feedback is satisfactory\n",
    "                if \"good\" in feedback.lower():\n",
    "                    print(\"Feedback was satisfactory.\")\n",
    "                    break  # Exit loop if feedback is satisfactory\n",
    "                else:\n",
    "                    print(\"Your introduction needs improvement.\")\n",
    "                    text_to_speech(\"Your introduction needs improvement. Please try again.\", self.speech_synthesizer)\n",
    "            else:\n",
    "                print(\"No valid introduction received. Please try again.\")\n",
    "                text_to_speech(\"No valid introduction received. Please try again.\", self.speech_synthesizer)\n",
    "\n",
    "            iteration_count += 1  # Increment the attempt count\n",
    "\n",
    "        # After 3 attempts, provide final feedback\n",
    "        if iteration_count == 3:\n",
    "            practice_feedback = \"You have made three attempts. Please practice your introduction more.\"\n",
    "            print(practice_feedback)\n",
    "            text_to_speech(practice_feedback, self.speech_synthesizer)\n",
    "\n",
    "        # Optionally, you could restart asking for introduction or move to the next stage\n",
    "        # Uncomment the following line if you want to ask again after three attempts\n",
    "        # await self.ask_for_introduction()  # Restart the process if needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################\n",
    "        # Optionally, you could restart asking for introduction or move to the next stage\n",
    "        # Uncomment the following line if you want to ask again after three attempts\n",
    "        # await self.ask_for_introduction()  # Restart the process if needed\n",
    "\n",
    "\n",
    "\n",
    "        # After 2 iterations, suggest practice and move on\n",
    "        # if \"good\" not in feedback.lower():\n",
    "        #     text_to_speech(\"Please practice this introduction more. Let's move on to the next question.\", self.speech_synthesizer)\n",
    "\n",
    "\n",
    "    async def ask_questions_based_on_resume(self, resume_text):\n",
    "        questions_prompt = f\"Based on the following resume, please ask relevant questions: {resume_text}\"\n",
    "        questions = self.llm.process(questions_prompt)\n",
    "        print(f\"AI: {questions}\")\n",
    "        text_to_speech(questions, self.speech_synthesizer)\n",
    "\n",
    "        while True:\n",
    "            user_response = await self.listen_for_speech()\n",
    "            if user_response:\n",
    "                print(f\"User: {user_response}\")\n",
    "                feedback = self.llm.process(user_response)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    async def main(self):\n",
    "        # Start with the welcome message\n",
    "        welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "        print(f\"AI: {welcome_message}\")\n",
    "        text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "        # Ask for the introduction twice\n",
    "        await self.ask_for_introduction()\n",
    "\n",
    "        # Load resume and process it after introductions\n",
    "        resume_path = r\"Resume\\Ankush Mahore.pdf\"  # Adjust this path to your resume file\n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume\n",
    "        await self.ask_questions_based_on_resume(resume_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "introducation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import PyPDF2\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def process(self, text):\n",
    "        self.memory.chat_memory.add_user_message(text)\n",
    "        start_time = time.time()\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        return response['text']\n",
    "\n",
    "    def load_resume(self, resume_path):\n",
    "        with open(resume_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            resume_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                resume_text += page.extract_text()\n",
    "        return resume_text.strip()\n",
    "\n",
    "    def save_memory(self, filepath='conversation_memory.pkl'):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.memory, f)\n",
    "        print(f\"Memory saved to {filepath}\")\n",
    "\n",
    "    def load_memory(self, filepath='conversation_memory.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.memory = pickle.load(f)\n",
    "            print(f\"Memory loaded from {filepath}\")\n",
    "        else:\n",
    "            print(f\"No memory file found at {filepath}, starting fresh.\")\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "    def load_conversation(self, filepath='conversation_log.txt'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as log_file:\n",
    "                previous_conversation = log_file.read()\n",
    "            print(\"Previous conversation loaded:\\n\", previous_conversation)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Unable to load conversation_log.txt. I don't have your last information available.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def setup_azure_speech(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"en-IN\"\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000')\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '4000')\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_recognizer\n",
    "\n",
    "\n",
    "def setup_azure_tts(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-IN-AaravNeural'\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_synthesizer\n",
    "\n",
    "\n",
    "def text_to_speech(text, speech_synthesizer):\n",
    "    ssml_text = f\"\"\"\n",
    "    <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-IN'>\n",
    "        <voice name='en-IN-AaravNeural'>\n",
    "            <prosody rate='medium'>\n",
    "                {text}\n",
    "            </prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesis complete\")\n",
    "        else:\n",
    "            print(f\"Speech synthesis failed: {speech_synthesis_result.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "        self.region = os.getenv(\"AZURE_REGION\")\n",
    "        self.speech_recognizer = setup_azure_speech(self.api_key, self.region)\n",
    "        self.speech_synthesizer = setup_azure_tts(self.api_key, self.region)\n",
    "        self.is_running = True\n",
    "\n",
    "    async def listen_for_speech(self):\n",
    "        print(\"Listening...\")\n",
    "        result = await self.recognize_speech()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        return None\n",
    "\n",
    "    async def recognize_speech(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        future = loop.create_future()\n",
    "\n",
    "        def recognized_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_result, evt.result)\n",
    "\n",
    "        def canceled_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_exception, Exception(f\"Speech recognition canceled: {evt.reason}\"))\n",
    "\n",
    "        self.speech_recognizer.recognized.connect(recognized_cb)\n",
    "        self.speech_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "        await loop.run_in_executor(None, self.speech_recognizer.start_continuous_recognition)\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(future, timeout=180.0)  # 180 second timeout\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Speech recognition timed out\")\n",
    "            result = None\n",
    "        finally:\n",
    "            await loop.run_in_executor(None, self.speech_recognizer.stop_continuous_recognition)\n",
    "\n",
    "        return result\n",
    "\n",
    "    async def ask_for_introduction(self):\n",
    "        iteration_count = 0\n",
    "        feedback = \"\"\n",
    "\n",
    "        while iteration_count < 3:  # Allow two attempts for the introduction\n",
    "            intro_prompt = \"Please introduce yourself.\"\n",
    "            print(f\"AI: {intro_prompt}\")\n",
    "            text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "            user_intro = await self.listen_for_speech()\n",
    "            if user_intro:\n",
    "                print(f\"User: {user_intro}\")\n",
    "                feedback = self.llm.process(user_intro)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "                # Suggest improvement if the introduction isn't good\n",
    "                if \"good\" not in feedback.lower():\n",
    "                    improvement_suggestion = (\n",
    "                        \"Consider adding more details about your key skills, \"\n",
    "                        \"specific experiences related to the job, and your motivations \"\n",
    "                        \"for applying to this company.\"\n",
    "                    )\n",
    "                    print(f\"AI: {improvement_suggestion}\")\n",
    "                    text_to_speech(improvement_suggestion, self.speech_synthesizer)\n",
    "\n",
    "            iteration_count += 1\n",
    "\n",
    "        # After two iterations, give final encouragement\n",
    "        final_encouragement = \"Thank you for your introductions. Let's move on to the next question.\"\n",
    "        print(f\"AI: {final_encouragement}\")\n",
    "        text_to_speech(final_encouragement, self.speech_synthesizer)\n",
    "\n",
    "    async def main(self):\n",
    "        # Start with the welcome message\n",
    "        welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "        print(f\"AI: {welcome_message}\")\n",
    "        text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "        # Ask for the introduction\n",
    "        await self.ask_for_introduction()\n",
    "\n",
    "        # Load resume and process it after introductions\n",
    "        resume_path = r\"Resume\\Ankush Mahore.pdf\"  # Adjust this path to your resume file\n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume (if needed)\n",
    "        # await self.ask_questions_based_on_resume(resume_text)  # Uncomment if required\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import pickle\n",
    "import PyPDF2\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from dotenv import load_dotenv\n",
    "from deepgram import DeepgramClient, SpeakOptions, LiveTranscriptionEvents, DeepgramClientOptions, LiveOptions, Microphone\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def text_to_speech(text):\n",
    "    \"\"\"Convert text to speech using the Deepgram API.\"\"\"\n",
    "    try:\n",
    "        deepgram = DeepgramClient(api_key=os.getenv(\"DEEPGRAM_API_KEY\"))\n",
    "        url = \"https://api.deepgram.com/v1/speak?model=aura-hera-en\"\n",
    "        api_key = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "        headers = {\"Authorization\": f\"Token {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "        options = SpeakOptions(\n",
    "            model=\"aura-zeus-en\",\n",
    "            encoding=\"linear16\",\n",
    "            container=\"wav\"\n",
    "        )\n",
    "        \n",
    "        SPEAK_OPTIONS = {\"text\": text}\n",
    "        filename = \"output.wav\"\n",
    "        response = deepgram.speak.v(\"1\").save(filename, SPEAK_OPTIONS, options)\n",
    "        audio = AudioSegment.from_wav(filename)\n",
    "        play(audio)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the language model processor.\"\"\"\n",
    "        self.llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\", groq_api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        # Load the system prompt from a file\n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def provide_feedback_on_introduction(self, introduction_text):\n",
    "        \"\"\"Analyze the introduction text and provide feedback on its effectiveness.\"\"\"\n",
    "        feedback_prompt = f\"Analyze this introduction: '{introduction_text}'. Provide feedback on its effectiveness.\"\n",
    "        response = self.conversation.invoke({\"text\": feedback_prompt})\n",
    "        self.save_conversation(feedback_prompt, response['text'])  # Save to conversation log\n",
    "        return response['text']\n",
    "\n",
    "    def process(self, text):\n",
    "        \"\"\"Process the user input text and get a response from the LLM.\"\"\"\n",
    "        self.memory.chat_memory.add_user_message(text)  # Add user message to memory\n",
    "        start_time = time.time()\n",
    "        # Get the response from the LLM\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])  # Add AI response to memory\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        self.save_conversation(text, response['text'])  # Save to conversation log\n",
    "        return response['text']\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        \"\"\"Save the conversation between user and AI to a log file.\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "class TranscriptCollector:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the transcript collector.\"\"\"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the transcript parts.\"\"\"\n",
    "        self.transcript_parts = []\n",
    "\n",
    "    def add_part(self, part):\n",
    "        \"\"\"Add a part to the transcript.\"\"\"\n",
    "        self.transcript_parts.append(part)\n",
    "\n",
    "    def get_full_transcript(self):\n",
    "        \"\"\"Return the full transcript as a single string.\"\"\"\n",
    "        return ' '.join(self.transcript_parts)\n",
    "\n",
    "transcript_collector = TranscriptCollector()\n",
    "\n",
    "async def get_transcript(callback):\n",
    "    \"\"\"Collect transcript from the microphone using Deepgram API.\"\"\"\n",
    "    transcription_complete = asyncio.Event()  # Event to signal transcription completion\n",
    "    try:\n",
    "        config = DeepgramClientOptions(options={\"keepalive\": \"true\"})\n",
    "        deepgram = DeepgramClient(\"\", config)\n",
    "        dg_connection = deepgram.listen.asyncwebsocket.v(\"1\")\n",
    "        print(\"Listening...\")\n",
    "\n",
    "        async def on_message(self, result, **kwargs):\n",
    "            \"\"\"Handle incoming transcription messages.\"\"\"\n",
    "            sentence = result.channel.alternatives[0].transcript\n",
    "            if not result.speech_final:\n",
    "                transcript_collector.add_part(sentence)\n",
    "            else:\n",
    "                transcript_collector.add_part(sentence)\n",
    "                full_sentence = transcript_collector.get_full_transcript()\n",
    "                if len(full_sentence.strip()) > 0:\n",
    "                    full_sentence = full_sentence.strip()\n",
    "                    print(f\"Human: {full_sentence}\")\n",
    "                    callback(full_sentence)\n",
    "                    transcript_collector.reset()\n",
    "                    transcription_complete.set()  # Signal to stop transcription and exit\n",
    "\n",
    "        dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n",
    "        options = LiveOptions(\n",
    "            model=\"nova-2\",\n",
    "            punctuate=True,\n",
    "            language=\"en-IN\",\n",
    "            encoding=\"linear16\",\n",
    "            channels=1,\n",
    "            sample_rate=16000,\n",
    "            endpointing=300,\n",
    "            smart_format=True,\n",
    "        )\n",
    "        await dg_connection.start(options)\n",
    "        microphone = Microphone(dg_connection.send)\n",
    "        microphone.start()\n",
    "        await transcription_complete.wait()  # Wait for the transcription to complete\n",
    "        microphone.finish()\n",
    "        await dg_connection.finish()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open socket: {e}\")\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the conversation manager.\"\"\"\n",
    "        self.transcription_response = \"\"\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "\n",
    "    async def main(self):\n",
    "        \"\"\"Main function to manage the conversation flow.\"\"\"\n",
    "        # Speak the welcome message\n",
    "        text_to_speech(self.welcome_message)\n",
    "\n",
    "        # Loop to ask for introduction up to 3 times\n",
    "        for attempt in range(3):\n",
    "            text_to_speech(f\"Please introduce yourself. This is attempt {attempt + 1} of 3.\")\n",
    "            await get_transcript(self.handle_transcription)\n",
    "            \n",
    "            # Provide feedback on the introduction\n",
    "            feedback = self.llm.provide_feedback_on_introduction(self.transcription_response)\n",
    "            text_to_speech(feedback)\n",
    "\n",
    "            # If feedback is positive, stop asking for further introductions\n",
    "            if \"good\" in feedback.lower():\n",
    "                text_to_speech(\"Great! Your introduction is good. Let's move on.\")\n",
    "                break\n",
    "            elif attempt < 2:  # Only ask again if not on the last attempt\n",
    "                text_to_speech(\"Let's try again and improve.\")\n",
    "\n",
    "        # After 3 attempts, suggest practicing more if the introduction is not satisfactory\n",
    "        if \"good\" not in feedback.lower():\n",
    "            text_to_speech(\"It seems like your introduction needs more practice. Please work on it and try again later.\")\n",
    "        \n",
    "        # End of the session\n",
    "        text_to_speech(\"Thank you for participating in the session.\")\n",
    "\n",
    "    def handle_transcription(self, transcription):\n",
    "        \"\"\"Handle the transcription and update the response.\"\"\"\n",
    "        self.transcription_response = transcription.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async def ask_for_introduction(self):\n",
    "    iteration_count = 0  # To count the number of attempts\n",
    "\n",
    "    while iteration_count < 3:  # Allow for up to 3 attempts\n",
    "        # Step 1: Ask for introduction\n",
    "        intro_prompt = \"Please introduce yourself.\"\n",
    "        print(f\"AI: {intro_prompt}\")\n",
    "        text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "        # Capture user's introduction\n",
    "        user_intro = await self.listen_for_speech()\n",
    "        if user_intro:\n",
    "            print(f\"User: {user_intro}\")\n",
    "\n",
    "            # Step 2: Analyze user's introduction and give feedback\n",
    "            feedback = self.llm.process(f\"Here is an introduction: {user_intro}. Give me feedback on the introduction, what is good, and what is missing.\")\n",
    "            print(f\"AI Feedback: {feedback}\")\n",
    "            text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "            # Step 3: Check if feedback is satisfactory\n",
    "            if \"good\" in feedback.lower():\n",
    "                print(\"Feedback was satisfactory.\")\n",
    "                return True  # Exit loop and move to the next stage (resume questions)\n",
    "            else:\n",
    "                print(\"Your introduction needs improvement.\")\n",
    "                text_to_speech(\"Your introduction needs improvement. Please try again.\", self.speech_synthesizer)\n",
    "        else:\n",
    "            print(\"No valid introduction received. Please try again.\")\n",
    "            text_to_speech(\"No valid introduction received. Please try again.\", self.speech_synthesizer)\n",
    "\n",
    "        iteration_count += 1  # Increment the attempt count\n",
    "\n",
    "    # After 3 attempts, provide final feedback\n",
    "    if iteration_count == 3:\n",
    "        practice_feedback = \"You have made three attempts. Please practice your introduction more.\"\n",
    "        print(practice_feedback)\n",
    "        text_to_speech(practice_feedback, self.speech_synthesizer)\n",
    "\n",
    "    return False  # Return false if the candidate couldn't provide a satisfactory introduction\n",
    "\n",
    "async def main(self):\n",
    "    # Start with the welcome message\n",
    "    welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "    print(f\"AI: {welcome_message}\")\n",
    "    text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "    # Ask for the introduction\n",
    "    introduction_satisfactory = await self.ask_for_introduction()\n",
    "\n",
    "    if introduction_satisfactory:\n",
    "        # Load resume and process it after satisfactory introductions\n",
    "        resume_path = r\"Resume\\Ankush Mahore.pdf\"  # Adjust this path to your resume file\n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume\n",
    "        await self.ask_questions_based_on_resume(resume_text)\n",
    "    else:\n",
    "        print(\"Moving on without resume questions due to unsatisfactory introduction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import asyncio\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class LanguageModelProcessor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.1-70b-versatile\",\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        with open('system_prompt2.txt', 'r') as file:\n",
    "            system_prompt = file.read().strip()\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "        ])\n",
    "        \n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    def process(self, text):\n",
    "        self.memory.chat_memory.add_user_message(text)\n",
    "        start_time = time.time()\n",
    "        response = self.conversation.invoke({\"text\": text})\n",
    "        end_time = time.time()\n",
    "        self.memory.chat_memory.add_ai_message(response['text'])\n",
    "        elapsed_time = int((end_time - start_time) * 1000)\n",
    "        print(f\"LLM ({elapsed_time}ms): {response['text']}\")\n",
    "        return response['text']\n",
    "\n",
    "    def load_resume(self, resume_path):\n",
    "        with open(resume_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            resume_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                resume_text += page.extract_text()\n",
    "        return resume_text.strip()\n",
    "\n",
    "    def save_memory(self, filepath='conversation_memory.pkl'):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.memory, f)\n",
    "        print(f\"Memory saved to {filepath}\")\n",
    "\n",
    "    def load_memory(self, filepath='conversation_memory.pkl'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                self.memory = pickle.load(f)\n",
    "            print(f\"Memory loaded from {filepath}\")\n",
    "        else:\n",
    "            print(f\"No memory file found at {filepath}, starting fresh.\")\n",
    "\n",
    "    def save_conversation(self, user_input, ai_response, filepath='conversation_log.txt'):\n",
    "        try:\n",
    "            with open(filepath, 'a', encoding='utf-8') as log_file:\n",
    "                log_file.write(f\"User: {user_input}\\nAI: {ai_response}\\n\\n\")\n",
    "        except UnicodeEncodeError as e:\n",
    "            print(f\"UnicodeEncodeError: {e}\")\n",
    "\n",
    "    def load_conversation(self, filepath='conversation_log.txt'):\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as log_file:\n",
    "                previous_conversation = log_file.read()\n",
    "            print(\"Previous conversation loaded:\\n\", previous_conversation)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Unable to load conversation_log.txt. I don't have your last information available.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def setup_azure_speech(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"en-IN\"\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, '5000')\n",
    "    speech_config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, '4000')\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_recognizer\n",
    "\n",
    "\n",
    "def setup_azure_tts(api_key, region):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=api_key, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-IN-AaravNeural'\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    return speech_synthesizer\n",
    "\n",
    "\n",
    "def text_to_speech(text, speech_synthesizer):\n",
    "    ssml_text = f\"\"\"\n",
    "    <speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-IN'>\n",
    "        <voice name='en-IN-AaravNeural'>\n",
    "            <prosody rate='medium'>\n",
    "                {text}\n",
    "            </prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesis complete\")\n",
    "        else:\n",
    "            print(f\"Speech synthesis failed: {speech_synthesis_result.reason}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.llm = LanguageModelProcessor()\n",
    "        self.api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "        self.region = os.getenv(\"AZURE_REGION\")\n",
    "        self.speech_recognizer = setup_azure_speech(self.api_key, self.region)\n",
    "        self.speech_synthesizer = setup_azure_tts(self.api_key, self.region)\n",
    "        self.is_running = True\n",
    "\n",
    "    async def listen_for_speech(self):\n",
    "        print(\"Listening...\")\n",
    "        result = await self.recognize_speech()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        return None\n",
    "\n",
    "    async def recognize_speech(self):\n",
    "        loop = asyncio.get_running_loop()\n",
    "        future = loop.create_future()\n",
    "\n",
    "        def recognized_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_result, evt.result)\n",
    "\n",
    "        def canceled_cb(evt):\n",
    "            if not future.done():\n",
    "                loop.call_soon_threadsafe(future.set_exception, Exception(f\"Speech recognition canceled: {evt.reason}\"))\n",
    "\n",
    "        self.speech_recognizer.recognized.connect(recognized_cb)\n",
    "        self.speech_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "        await loop.run_in_executor(None, self.speech_recognizer.start_continuous_recognition)\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(future, timeout=180.0)  # 180 second timeout\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Speech recognition timed out\")\n",
    "            result = None\n",
    "        finally:\n",
    "            await loop.run_in_executor(None, self.speech_recognizer.stop_continuous_recognition)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    #####################################################################################################\n",
    "    # async def ask_for_introduction(self):\n",
    "    #     iteration_count = 0\n",
    "    #     feedback = \"\"\n",
    "\n",
    "    #     while \"good\" not in feedback.lower() and iteration_count < 2:\n",
    "    #         # First introduction\n",
    "    #         intro_prompt = \"Please introduce yourself.\"\n",
    "    #         print(f\"AI: {intro_prompt}\")\n",
    "    #         text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "    #         user_intro = await self.listen_for_speech()\n",
    "    #         if user_intro:\n",
    "    #             print(f\"User: {user_intro}\")\n",
    "    #             feedback = self.llm.process(user_intro)\n",
    "    #             print(f\"AI: {feedback}\")\n",
    "    #             text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    #         iteration_count += 1\n",
    "\n",
    "    ######################################################################################################\n",
    "\n",
    "    # async def ask_for_introduction(self):\n",
    "    #     iteration_count = 0  # To count the number of attempts\n",
    "\n",
    "    #     while iteration_count < 3:  # Allow for up to 3 attempts\n",
    "    #         # Step 1: Ask for introduction\n",
    "    #         intro_prompt = \"Please introduce yourself.\"\n",
    "    #         print(f\"AI: {intro_prompt}\")\n",
    "    #         text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "    #         # Capture user's introduction\n",
    "    #         user_intro = await self.listen_for_speech()\n",
    "    #         if user_intro:\n",
    "    #             print(f\"User: {user_intro}\")\n",
    "\n",
    "    #             # Step 2: Analyze user's introduction and give feedback\n",
    "    #             feedback = self.llm.process(f\"Here is an introduction: {user_intro}. Give me feedback on the introduction, what is good, and what is missing.\")\n",
    "    #             print(f\"AI Feedback: {feedback}\")\n",
    "    #             text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    #             # Step 3: Check if feedback is satisfactory\n",
    "    #             if \"good\" in feedback.lower():\n",
    "    #                 print(\"Feedback was satisfactory.\")\n",
    "    #                 break  # Exit loop if feedback is satisfactory\n",
    "    #             else:\n",
    "    #                 print(\"Your introduction needs improvement.\")\n",
    "    #                 text_to_speech(\"Your introduction needs improvement. Please try again.\", self.speech_synthesizer)\n",
    "    #         else:\n",
    "    #             print(\"No valid introduction received. Please try again.\")\n",
    "    #             text_to_speech(\"No valid introduction received. Please try again.\", self.speech_synthesizer)\n",
    "\n",
    "    #         iteration_count += 1  # Increment the attempt count\n",
    "\n",
    "    #     # After 3 attempts, provide final feedback\n",
    "    #     if iteration_count == 3:\n",
    "    #         practice_feedback = \"You have made three attempts. Please practice your introduction more.\"\n",
    "    #         print(practice_feedback)\n",
    "    #         text_to_speech(practice_feedback, self.speech_synthesizer)\n",
    "    #     # Optionally, you could restart asking for introduction or move to the next stage\n",
    "    #     # Uncomment the following line if you want to ask again after three attempts\n",
    "    #     # await self.ask_for_introduction()  # Restart the process if needed\n",
    "\n",
    "\n",
    "\n",
    "    async def ask_for_introduction(self):\n",
    "        iteration_count = 0  # To count the number of attempts\n",
    "\n",
    "        while iteration_count < 3:  # Allow for up to 3 attempts\n",
    "            # Step 1: Ask for introduction\n",
    "            intro_prompt = \"Please introduce yourself.\"\n",
    "            print(f\"AI: {intro_prompt}\")\n",
    "            text_to_speech(intro_prompt, self.speech_synthesizer)\n",
    "\n",
    "            # Capture user's introduction\n",
    "            user_intro = await self.listen_for_speech()\n",
    "            if user_intro:\n",
    "                print(f\"User: {user_intro}\")\n",
    "\n",
    "                # Step 2: Analyze user's introduction and give feedback\n",
    "                feedback = self.llm.process(f\"Here is an introduction: {user_intro}. Give me feedback on the introduction, what is good, and what is missing.\")\n",
    "                print(f\"AI Feedback: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "                # Step 3: Check if feedback is satisfactory\n",
    "                if \"good\" in feedback.lower():\n",
    "                    print(\"Feedback was satisfactory.\")\n",
    "                    return True  # Exit loop and move to the next stage (resume questions)\n",
    "                else:\n",
    "                    print(\"Your introduction needs improvement.\")\n",
    "                    text_to_speech(\"Your introduction needs improvement. Please try again.\", self.speech_synthesizer)\n",
    "            else:\n",
    "                print(\"No valid introduction received. Please try again.\")\n",
    "                text_to_speech(\"No valid introduction received. Please try again.\", self.speech_synthesizer)\n",
    "\n",
    "            iteration_count += 1  # Increment the attempt count\n",
    "\n",
    "        # After 3 attempts, provide final feedback\n",
    "        if iteration_count == 3:\n",
    "            practice_feedback = \"You have made three attempts. Please practice your introduction more.\"\n",
    "            print(practice_feedback)\n",
    "            text_to_speech(practice_feedback, self.speech_synthesizer)\n",
    "\n",
    "        return False  # Return false if the candidate couldn't provide a satisfactory introduction\n",
    "\n",
    "###############################################################\n",
    "        # Optionally, you could restart asking for introduction or move to the next stage\n",
    "        # Uncomment the following line if you want to ask again after three attempts\n",
    "        # await self.ask_for_introduction()  # Restart the process if needed\n",
    "\n",
    "\n",
    "\n",
    "        # After 2 iterations, suggest practice and move on\n",
    "        # if \"good\" not in feedback.lower():\n",
    "        #     text_to_speech(\"Please practice this introduction more. Let's move on to the next question.\", self.speech_synthesizer)\n",
    "\n",
    "\n",
    "    async def ask_questions_based_on_resume(self, resume_text):\n",
    "        questions_prompt = f\"Based on the following resume, please ask relevant questions: {resume_text}\"\n",
    "        questions = self.llm.process(questions_prompt)\n",
    "        print(f\"AI: {questions}\")\n",
    "        text_to_speech(questions, self.speech_synthesizer)\n",
    "\n",
    "        while True:\n",
    "            user_response = await self.listen_for_speech()\n",
    "            if user_response:\n",
    "                print(f\"User: {user_response}\")\n",
    "                feedback = self.llm.process(user_response)\n",
    "                print(f\"AI: {feedback}\")\n",
    "                text_to_speech(feedback, self.speech_synthesizer)\n",
    "\n",
    "    async def main(self):\n",
    "        # Start with the welcome message\n",
    "        welcome_message = \"I am GetScreened PrepGuru. I will guide you step by step to improve your interview skills and help you become a better version of yourself.\"\n",
    "        print(f\"AI: {welcome_message}\")\n",
    "        text_to_speech(welcome_message, self.speech_synthesizer)\n",
    "\n",
    "        # Ask for the introduction twice\n",
    "        await self.ask_for_introduction()\n",
    "\n",
    "        # Load resume and process it after introductions\n",
    "        resume_path = r\"Resume\\Abhinav Anand Resume.pdf\"  # Adjust this path to your resume file  \n",
    "        resume_text = self.llm.load_resume(resume_path)\n",
    "\n",
    "        # Ask questions based on the resume\n",
    "        await self.ask_questions_based_on_resume(resume_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = ConversationManager()\n",
    "    asyncio.run(manager.main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: c3c58509-b4b6-4f54-932a-6c6951d87ef0\n",
      "Full Name: Sushrut Rajeshwar Nistane\n",
      "Email: sushrutnistane097@gmail.com\n",
      "Resume URL: https://getscreenedstoragebucketf24ed-devget.s3.amazonaws.com/public/1724521431224_Sushrut Nistane Resume  pdf (3).pdf\n",
      "Resume downloaded and saved as resumes\\Sushrut_Rajeshwar_Nistane_resume.pdf\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "API_ENDPOINT = \"https://sy5r6puueraf3gty6ujp5iajmi.appsync-api.ap-south-1.amazonaws.com/graphql\"\n",
    "API_KEY = \"da2-c3tlmtun7vcz5e2t7mcfizxma4\"\n",
    "RESUME_FOLDER = \"resumes\"  # Folder to save resumes\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# GraphQL query for listing candidate profiles with pagination\n",
    "list_candidate_profiles_query = \"\"\"\n",
    "query ListCandidateProfiles(\n",
    "  $filter: ModelCandidateProfileFilterInput\n",
    "  $limit: Int\n",
    "  $nextToken: String\n",
    ") {\n",
    "  listCandidateProfiles(\n",
    "    filter: $filter\n",
    "    limit: $limit\n",
    "    nextToken: $nextToken\n",
    "  ) {\n",
    "    items {\n",
    "      id\n",
    "      fullName\n",
    "      email\n",
    "      resumeURL\n",
    "    }\n",
    "    nextToken\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Function to download a file from a URL and save it to a folder\n",
    "def download_resume(resume_url, full_name):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(RESUME_FOLDER):\n",
    "        os.makedirs(RESUME_FOLDER)\n",
    "\n",
    "    # Determine the file name\n",
    "    resume_file_name = f\"{full_name.replace(' ', '_')}_resume.pdf\"\n",
    "    resume_path = os.path.join(RESUME_FOLDER, resume_file_name)\n",
    "\n",
    "    # Download the resume\n",
    "    response = requests.get(resume_url)\n",
    "\n",
    "    # Save the resume to the folder\n",
    "    with open(resume_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(f\"Resume downloaded and saved as {resume_path}\")\n",
    "\n",
    "# Fetch candidate profiles and download their resumes\n",
    "def fetch_candidate_profiles(email, limit=10):\n",
    "    profiles = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Payload with the query, variables, and filter for the specific email\n",
    "        payload = {\n",
    "            \"query\": list_candidate_profiles_query,\n",
    "            \"variables\": {\n",
    "                \"filter\": {\n",
    "                    \"email\": {\n",
    "                        \"eq\": email\n",
    "                    }\n",
    "                },\n",
    "                \"limit\": limit,\n",
    "                \"nextToken\": next_token\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Make the request to the GraphQL API\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=payload)\n",
    "\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract the candidate profiles and nextToken for pagination\n",
    "        result = data.get('data', {}).get('listCandidateProfiles', {})\n",
    "        profiles.extend(result.get('items', []))\n",
    "        next_token = result.get('nextToken')\n",
    "\n",
    "        # If there's no more data to fetch, exit the loop\n",
    "        if not next_token:\n",
    "            break\n",
    "\n",
    "    # Download the resumes\n",
    "    for profile in profiles:\n",
    "        full_name = profile.get('fullName', 'Unknown')\n",
    "        email = profile.get('email', 'Unknown')\n",
    "        resume_url = profile.get('resumeURL', None)\n",
    "\n",
    "        print(f\"ID: {profile['id']}\")\n",
    "        print(f\"Full Name: {full_name}\")\n",
    "        print(f\"Email: {email}\")\n",
    "        print(f\"Resume URL: {resume_url}\")\n",
    "\n",
    "        # Download the resume if the URL exists\n",
    "        if resume_url:\n",
    "            download_resume(resume_url, full_name)\n",
    "        else:\n",
    "            print(f\"No resume available for {full_name}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Fetch and download resumes for the specified email with pagination\n",
    "fetch_candidate_profiles('sushrutnistane097@gmail.com')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
